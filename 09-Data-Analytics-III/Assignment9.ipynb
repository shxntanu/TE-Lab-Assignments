{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd7a235b",
   "metadata": {},
   "source": [
    "# Assignment 9\n",
    "\n",
    "## Data Analytics III\n",
    "\n",
    "1. Implement Simple Naïve Bayes classification algorithm using Python/R on iris.csv dataset.\n",
    "2. Compute Confusion matrix to find TP, FP, TN, FN, Accuracy, Error rate, Precision, Recall on the given dataset. Provide the codes with outputs and explain everything that you do in this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b33c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0614854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "  species  \n",
       "0  setosa  \n",
       "1  setosa  \n",
       "2  setosa  \n",
       "3  setosa  \n",
       "4  setosa  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# load the built in Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['species'] = iris.target_names[iris.target]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c98875-4ae8-4299-b56a-e55e4c258e22",
   "metadata": {},
   "source": [
    "## Naive Bayes using Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1bd7f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop([\"species\"], axis=1)\n",
    "y = df[\"species\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66dc1a35-324f-49b7-8b32-19d14d47f24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6a1d6ee-7b17-4a95-8c46-30909d199209",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5abd18c-f8ca-48ac-8112-ff53513549ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9580715-c918-4505-b6db-3abf334dc473",
   "metadata": {},
   "source": [
    "## Naiye Bayes from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c57e77b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_by_class(data):\n",
    "  \"\"\"\n",
    "  Separates data into dictionaries grouped by class labels.\n",
    "\n",
    "  Args:\n",
    "      data: A numpy array of the features.\n",
    "      target: A numpy array of the corresponding class labels.\n",
    "\n",
    "  Returns:\n",
    "      A dictionary where keys are class labels and values are lists of data points belonging to that class (except for the last column as that is what we want to predict).\n",
    "  \"\"\"\n",
    "  separated = {}\n",
    "  for i in range(len(data)):\n",
    "    row = data.iloc[i]\n",
    "    class_label = row[-1]\n",
    "    if class_label not in separated:\n",
    "      separated[class_label] = []\n",
    "    separated[class_label].append(row[:-1].tolist())\n",
    "  return separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "624f0c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_by_class(data):\n",
    "  \"\"\"\n",
    "  Summarizes data by class, calculating mean and standard deviation for each feature.\n",
    "\n",
    "  Args:\n",
    "      data: A list of data points (each data point is a list of features).\n",
    "\n",
    "  Returns:\n",
    "      A dictionary where keys are feature indices and values are dictionaries containing mean and standard deviation for each feature (i.e. column).\n",
    "  \"\"\"\n",
    "  separated = separate_by_class(data.copy())\n",
    "  summaries = {}\n",
    "  \n",
    "  for class_label, examples in separated.items():\n",
    "\n",
    "    # For every label, get the avg of all the attributes (i.e. columns) for that label\n",
    "    summaries[class_label] = [(sum(attribute) / (len(examples))) for attribute in zip(*examples)]\n",
    "\n",
    "    \"\"\"\n",
    "      summaries = {\n",
    "        'Iris-setosa': \n",
    "                    [\n",
    "                      25.5,\n",
    "                      5.005999999999999,\n",
    "                      3.4180000000000006,\n",
    "                      1.464,\n",
    "                      0.2439999999999999\n",
    "                    ],\n",
    "        'Iris-versicolor': \n",
    "                    [ \n",
    "                      75.5,\n",
    "                      5.936,,\n",
    "                      2.7700000000000005,\n",
    "                      4.26,\n",
    "                      1.3259999999999998\n",
    "                    ],\n",
    "        'Iris-virginica': \n",
    "                    [\n",
    "                      125.5,\n",
    "                      6.587999999999998,\n",
    "                      2.9739999999999998,\n",
    "                      5.552,\n",
    "                      2.026\n",
    "                    ]\n",
    "      } \n",
    "    \"\"\"\n",
    "    # For every attribute of every label, add the std dev. of that attribute as well\n",
    "    for i in range(len(summaries[class_label])):\n",
    "      variance = sum((val - summaries[class_label][i])**2 for val in [example[i] for example in examples])\n",
    "      std = np.sqrt(variance / (len(examples) - 1)) if len(examples) > 1 else 0\n",
    "      summaries[class_label][i] = (summaries[class_label][i], std)\n",
    "\n",
    "    \"\"\"\n",
    "      summaries = {\n",
    "        'Iris-setosa': [\n",
    "          (25.5, 14.577379737113251),\n",
    "          (5.005999999999999, 0.3524896872134512),\n",
    "          (3.4180000000000006, 0.38102439795469095),\n",
    "          (1.464, 0.1735111594364455),\n",
    "          (0.2439999999999999, 0.10720950308167837)\n",
    "        ],\n",
    "        'Iris-versicolor': [\n",
    "          (75.5, 14.577379737113251),\n",
    "          (5.936, 0.5161711470638635),\n",
    "          (2.7700000000000005, 0.3137983233784114),\n",
    "          (4.26, 0.46991097723995806),\n",
    "          (1.3259999999999998, 0.197752680004544)\n",
    "        ],\n",
    "        'Iris-virginica': [\n",
    "          (125.5, 14.577379737113251),\n",
    "          (6.587999999999998, 0.635879593274432),\n",
    "          (2.9739999999999998, 0.3224966381726376),\n",
    "          (5.552, 0.5518946956639835),\n",
    "          (2.026, 0.27465005563666733)\n",
    "        ]\n",
    "      }\n",
    "    \"\"\"\n",
    "  return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d52ba19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38031/3214133838.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  class_label = row[-1]\n"
     ]
    }
   ],
   "source": [
    "summaries = summarize_by_class(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b14bd6",
   "metadata": {},
   "source": [
    "Formula for the probability density function is:\n",
    "\n",
    "$f(x | μ, σ) = \\frac{1} {√2πσ^{2}} e^{-\\frac{(x - μ)^2} {2 σ^2}}$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $x$ is the value for which we want to calculate the probability.\n",
    "- $μ$ is the mean of the distribution.\n",
    "- $σ$ is the standard deviation of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6737897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probability(x, mean, std):\n",
    "  \"\"\"\n",
    "  Calculates the probability of a value given a normal distribution.\n",
    "\n",
    "  Args:\n",
    "      x: The feature value.\n",
    "      mean: The mean of the feature.\n",
    "      std: The standard deviation of the feature.\n",
    "\n",
    "  Returns:\n",
    "      The probability of the feature value.\n",
    "  \"\"\"\n",
    "  from math import pi, exp\n",
    "  exponent = - (x - mean) ** 2 / (2 * std**2)\n",
    "  return (1 / (std * np.sqrt(2 * pi))) * exp(exponent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f720687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_probability(data, summaries, class_label):\n",
    "  \"\"\"\n",
    "  Calculates the probability of a data point belonging to a specific class.\n",
    "\n",
    "  Args:\n",
    "      data: A dictionary where keys are class labels and values are lists of data points belonging to that class.\n",
    "      target: A numpy array of the class labels for the training data.\n",
    "      summary: A dictionary containing summary statistics for each feature.\n",
    "      test_data: A single data point to predict the class for.\n",
    "\n",
    "  Returns:\n",
    "      A dictionary where keys are class labels and values are their corresponding posterior probabilities for the test data.\n",
    "  \"\"\"\n",
    "  probability = 1\n",
    "  for i in range(len(data)):\n",
    "    mean, std = summaries[class_label][i]\n",
    "    probability *= calculate_probability(data[i], mean, std)\n",
    "  return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a28ec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, summaries):\n",
    "  \"\"\"\n",
    "  Predicts the class label with the highest probability for a data point.\n",
    "\n",
    "  Args:\n",
    "      data: A dictionary where keys are class labels and values are lists of data points belonging to that class.\n",
    "      target: A numpy array of the class labels for the training data.\n",
    "      summary: A dictionary containing summary statistics for each feature.\n",
    "      test_data: A single data point to predict the class for.\n",
    "\n",
    "  Returns:\n",
    "      The predicted class label.\n",
    "  \"\"\"\n",
    "  probabilities = {class_label: calculate_class_probability(data, summaries, class_label) for class_label in summaries.keys()}\n",
    "  return max(probabilities, key=probabilities.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9da1ae33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         setosa\n",
       "1         setosa\n",
       "2         setosa\n",
       "3         setosa\n",
       "4         setosa\n",
       "         ...    \n",
       "145    virginica\n",
       "146    virginica\n",
       "147    virginica\n",
       "148    virginica\n",
       "149    virginica\n",
       "Length: 150, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = df.apply(lambda row: predict(row[:-1].tolist(), summaries), axis=1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afa26f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(df['species'], predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0790b754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(df['species'], predictions, average='weighted')\n",
    "print(\"F1 Score:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
